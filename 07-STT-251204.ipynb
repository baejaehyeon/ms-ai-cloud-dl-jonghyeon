{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e00624a",
   "metadata": {},
   "source": [
    "STT(Speech To Text) : 음성 입력 => 텍스트 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac1bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo : \n",
    "\n",
    "    # 오디오 파일 경로 반환\n",
    "    def change_audio(audio_path) : \n",
    "        return audio_path\n",
    "    \n",
    "    with gr.Row() :\n",
    "        input_mic = gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"Input Microphone\")   # 마이크로 음성 녹음\n",
    "        input_file = gr.Audio(sources=\"upload\", type=\"filepath\", label=\"Input File\")            # 녹음된 파일 업로드\n",
    "\n",
    "        output_text = gr.Textbox(label=\"Transcription Output\")  # 텍스트 박스\n",
    "\n",
    "        # 마이크로 음성 녹음 완료 시, 녹음된 파일 경로를 output_text에 표출\n",
    "        input_mic.change(fn=change_audio, inputs=[input_mic], outputs=[output_text])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdbce17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks() as demo : \n",
    "\n",
    "    # 오디오 파일 경로 반환\n",
    "    def request_stt(audio_path) :\n",
    "        # 1. Endpoint\n",
    "        endpoint = \"https://eastus.stt.speech.microsoft.com/speech/recognition/conversation/cognitiveservices/v1?language=ko-KR&format=detailed\"\n",
    "\n",
    "        # 2. Header\n",
    "        headers = {\n",
    "            \"Content-Type\" : \"audio/wav\",\n",
    "            \"Ocp-Apim-Subscription-Key\" : os.getenv(\"STT_OCP_APIM_SUB_KEY\")\n",
    "        }\n",
    "\n",
    "        # 3. Body : Audio file => binary\n",
    "        with open(audio_path, \"rb\") as audio_file : \n",
    "            audio_data = audio_file.read()\n",
    "\n",
    "        body = audio_data\n",
    "\n",
    "        # request Audio => Text\n",
    "        response = requests.post(endpoint, headers=headers, data=body)\n",
    "\n",
    "        if response.status_code != 200 :\n",
    "            print(f\"Http Error {response.status_code} : {response.reason}\")\n",
    "            return None\n",
    "        \n",
    "        import json\n",
    "\n",
    "        # String => Dictionary\n",
    "        result_json = json.loads(response.text)\n",
    "\n",
    "        if result_json.get(\"RecognitionStatus\") != \"Success\" : \n",
    "            print(\"Response Error \", result_json.get(\"RecognitionStatus\"))\n",
    "            return None\n",
    "        \n",
    "        # return Audio => Text\n",
    "        return result_json.get(\"DisplayText\")\n",
    "\n",
    "    def change_audio(audio_path) :\n",
    "        return audio_path\n",
    "    \n",
    "    def click_send(audio_path) :\n",
    "        if audio_path is None : \n",
    "            return \"마이크를 녹음해주세요.\"\n",
    "        \n",
    "        return request_stt(audio_path)\n",
    "\n",
    "    with gr.Row() :\n",
    "        input_mic = gr.Audio(sources=\"microphone\", type=\"filepath\", label=\"Input Microphone\")   # 마이크로 음성 녹음\n",
    "        input_file = gr.Audio(sources=\"upload\", type=\"filepath\", label=\"Input File\")            # 녹음된 파일 업로드\n",
    "\n",
    "        file_path_text = gr.Textbox(label=\"Transcription Output\")  # 텍스트 박스\n",
    "\n",
    "    # 마이크로 음성 녹음 완료 시, 녹음된 파일 경로를 output_text에 표출\n",
    "    input_mic.change(fn=change_audio, inputs=[input_mic], outputs=[file_path_text])\n",
    "    \n",
    "    # 녹음 이후, 전송 버튼 클릭 시, click_send에서 녹음 여부 판단 후, Audio => 텍스트로 변환하여 변환된 텍스트를 output_text에 출력\n",
    "    send_button = gr.Button(\"전송\")\n",
    "    output_text = gr.Textbox(label=\"결과 텍스트\")\n",
    "\n",
    "    send_button.click(fn=click_send, inputs=[input_file], outputs=[output_text])\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# .env 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
