{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a4cb6ec",
   "metadata": {},
   "source": [
    "OpenCV(Open Computer Vision)은, 이미지 및 비디오 데이터를 처리, 분석, 조작을 쉽게 할 수 있도록 만들어진 오픈 소스 라이브러리\n",
    "- 데이터 기반 학습, 지능적 예측과 같은 AI와는 다르게 규칙 및 알고리즘 기반으로 설계 및 구성되어 있으므로, 그 자체로 AI라고 볼 수 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c60f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install gradio\n",
    "#%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34005d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# 얼굴 감지\n",
    "haarcascade_frontalface_default\t가장 표준적인 정면 얼굴 감지.\t학습 시작 시 사용자 인증/출석 체크의 기본 단계로 활용.\n",
    "haarcascade_frontalface_alt\tdefault보다 조금 더 정교한 정면 얼굴 감지.\tdefault 실패 시 AI 면접 및 집중도 모니터링의 정확도를 높이기 위한 대안 모델.\n",
    "haarcascade_frontalface_alt2\t성능과 속도의 균형을 잡은 정면 얼굴 감지.\t다양한 조명 조건에서의 얼굴 추적에 활용.\n",
    "haarcascade_profileface\t사람의 측면 얼굴 감지.\t집중도 모니터링 시 학습자가 화면에서 고개를 돌리고 있는지(딴짓 여부) 파악.\n",
    "\n",
    "# 눈 & 표정 & 시선 감지\n",
    "haarcascade_eye\t일반적인 눈 감지.\t졸음 감지의 기초 로직(눈 깜빡임 빈도 분석).\n",
    "haarcascade_eye_tree_eyeglasses\t안경 착용자의 눈 감지에 특화.\t안경을 쓴 학습자의 시선 처리 정확도 향상 (AI 면접, 발표 코칭).\n",
    "haarcascade_lefteye_2splits\t왼쪽 눈만 감지.\t보다 정밀한 시선 방향 추적 (학습자가 화면의 특정 영역을 보고 있는지 분석).\n",
    "haarcascade_righteye_2splits\t오른쪽 눈만 감지.\t보다 정밀한 시선 방향 추적.\n",
    "haarcascade_smile\t입꼬리의 움직임을 감지하여 웃는 표정 감지.\tAI 면접 기능에서 지원자의 표정 안정성 및 미소 유지 여부 피드백.\n",
    "\n",
    "# 신체 자세 및 행동 감지\n",
    "haarcascade_upperbody\t사람의 상반신 감지 (머리, 어깨).\t발표 코칭 및 AI 면접 시 카메라 앵글 내 자세 안정성 체크.\n",
    "haarcascade_lowerbody\t사람의 하반신 감지.\t학습자가 자리에서 일어섰는지 (자리 이탈) 감지하여 집중도 저하 알림.\n",
    "haarcascade_fullbody\t사람의 전신 감지.\t발표 코칭 시 발표자의 전신 제스처 변화 분석 (활용 빈도는 낮을 수 있음).\n",
    "\n",
    "# 기타 객체 감지 및 동물\n",
    "haarcascade_frontalcatface\t고양이 얼굴 감지.\t활용도 낮음. (단, 펫캠 기반 학습 환경 시 활용 가능)\n",
    "haarcascade_frontalcatface_extended\t확장된 고양이 얼굴 감지.\t활용도 낮음.\n",
    "haarcascade_russian_plate_number\t러시아어 차량 번호판 감지.\t활용도 없음 (학습 플랫폼과 무관).\n",
    "haarcascade_license_plate_rus_16stages\t16단계의 러시아어 차량 번호판 감지 (더 정교함).\t활용도 없음 (학습 플랫폼과 무관).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8b33e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute '_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 120\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# 웹캠에서 Face 감지 결과를 표출할 컴포넌트\u001b[39;00m\n\u001b[32m    118\u001b[39m     result_image = gr.Image(label=\u001b[33m\"\u001b[39m\u001b[33m검출 결과\u001b[39m\u001b[33m\"\u001b[39m, interactive=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43mstream_image\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_webcam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstream_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_size\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mresult_image\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m cascade_dropdown.change(fn=change_cascade, inputs=[cascade_dropdown], outputs=[cascade_dropdown])\n\u001b[32m    122\u001b[39m apply_button.click(fn=click_apply, inputs=[scale_factor_textbox, min_neighbors_textbox, min_size_text], outputs=[scale_factor, min_neighbors, min_size])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EL32\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\events.py:749\u001b[39m, in \u001b[36mEventListener._setup.<locals>.event_trigger\u001b[39m\u001b[34m(block, fn, inputs, outputs, api_name, api_description, scroll_to_output, show_progress, show_progress_on, queue, batch, max_batch_size, preprocess, postprocess, cancels, trigger_mode, js, concurrency_limit, concurrency_id, api_visibility, time_limit, stream_every, key, validator)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _callback:\n\u001b[32m    748\u001b[39m     _callback(block)\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Dependency(block, \u001b[43mdep\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, dep_index, fn)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EL32\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\block_function.py:142\u001b[39m, in \u001b[36mBlockFunction.get_config\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    140\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._id,\n\u001b[32m    141\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtargets\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.targets,\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43m[\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_id\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mblock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m    143\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [block._id \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.outputs],\n\u001b[32m    144\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbackend_fn\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    145\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mjs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.js,\n\u001b[32m    146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mqueue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.queue,\n\u001b[32m    147\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.api_name,\n\u001b[32m    148\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_description\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.api_description,\n\u001b[32m    149\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mscroll_to_output\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.scroll_to_output,\n\u001b[32m    150\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshow_progress\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.show_progress,\n\u001b[32m    151\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshow_progress_on\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_progress_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    153\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m [block._id \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_progress_on],\n\u001b[32m    154\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.batch,\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax_batch_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.max_batch_size,\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcancels\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.cancels,\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtypes\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    158\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mgenerator\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.types_generator,\n\u001b[32m    159\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcancel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.is_cancel_function,\n\u001b[32m    160\u001b[39m         },\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcollects_event_data\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.collects_event_data,\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrigger_after\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.trigger_after,\n\u001b[32m    163\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrigger_only_on_success\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.trigger_only_on_success,\n\u001b[32m    164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrigger_only_on_failure\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.trigger_only_on_failure,\n\u001b[32m    165\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrigger_mode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.trigger_mode,\n\u001b[32m    166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_visibility\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.api_visibility,\n\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrendered_in\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.rendered_in._id \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rendered_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    168\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrender_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.renderable._id \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.renderable \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mconnection\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.connection,\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.time_limit,\n\u001b[32m    171\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstream_every\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.stream_every,\n\u001b[32m    172\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mevent_specific_args\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.event_specific_args,\n\u001b[32m    173\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcomponent_prop_inputs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.component_prop_inputs,\n\u001b[32m    174\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mjs_implementation\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fn, \u001b[33m\"\u001b[39m\u001b[33m__js_implementation__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    175\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\EL32\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\block_function.py:142\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    140\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._id,\n\u001b[32m    141\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtargets\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.targets,\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[43mblock\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_id\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.inputs],\n\u001b[32m    143\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m: [block._id \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.outputs],\n\u001b[32m    144\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbackend_fn\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    145\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mjs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.js,\n\u001b[32m    146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mqueue\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.queue,\n\u001b[32m    147\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_name\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.api_name,\n\u001b[32m    148\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_description\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.api_description,\n\u001b[32m    149\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mscroll_to_output\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.scroll_to_output,\n\u001b[32m    150\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshow_progress\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.show_progress,\n\u001b[32m    151\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshow_progress_on\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    152\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_progress_on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    153\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m [block._id \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.show_progress_on],\n\u001b[32m    154\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.batch,\n\u001b[32m    155\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmax_batch_size\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.max_batch_size,\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcancels\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.cancels,\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtypes\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m    158\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mgenerator\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.types_generator,\n\u001b[32m    159\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mcancel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.is_cancel_function,\n\u001b[32m    160\u001b[39m         },\n\u001b[32m    161\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcollects_event_data\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.collects_event_data,\n\u001b[32m    162\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrigger_after\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.trigger_after,\n\u001b[32m    163\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrigger_only_on_success\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.trigger_only_on_success,\n\u001b[32m    164\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrigger_only_on_failure\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.trigger_only_on_failure,\n\u001b[32m    165\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtrigger_mode\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.trigger_mode,\n\u001b[32m    166\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mapi_visibility\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.api_visibility,\n\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrendered_in\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.rendered_in._id \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rendered_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    168\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrender_id\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.renderable._id \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.renderable \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    169\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mconnection\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.connection,\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtime_limit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.time_limit,\n\u001b[32m    171\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstream_every\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.stream_every,\n\u001b[32m    172\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mevent_specific_args\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.event_specific_args,\n\u001b[32m    173\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mcomponent_prop_inputs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.component_prop_inputs,\n\u001b[32m    174\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mjs_implementation\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.fn, \u001b[33m\"\u001b[39m\u001b[33m__js_implementation__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m    175\u001b[39m     }\n",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute '_id'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import gradio as gr\n",
    "from PIL import Image\n",
    "\n",
    "# cv2.data.haarcascades => 'c:\\\\Users\\\\EL32\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python311\\\\Lib\\\\site-packages\\\\cv2\\\\data\\\\'\n",
    "cascade_file = cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    "\n",
    "# Haar Cascade 분류기 객체 생성. 앞서 지정한 XML 파일에 저장된 사전 학습된 특징 데이터를 메모리에 로드하며, 이미지에서 얼굴을 감지할 준비가 완료\n",
    "face_cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "HARR_CASCADES = [\n",
    "    (\"상반신 감지\", \"haarcascade_upperbody.xml\"),\n",
    "    (\"안경 낀 눈 감지\", \"haarcascade_eye_tree_eyeglasses.xml\"),\n",
    "    (\"눈 감지\", \"haarcascade_eye.xml\"),\n",
    "    (\"고양이 얼굴(확장형) 감지\", \"haarcascade_frontalcatface_extended.xml\"),\n",
    "    (\"고양이 얼굴 감지\", \"haarcascade_frontalcatface.xml\"),\n",
    "    (\"얼굴 감지 (alt 트리 버전)\", \"haarcascade_frontalface_alt_tree.xml\"),\n",
    "    (\"얼굴 감지 (alt 버전 1)\", \"haarcascade_frontalface_alt.xml\"),\n",
    "    (\"얼굴 감지 (alt 버전 2)\", \"haarcascade_frontalface_alt2.xml\"),\n",
    "    (\"일반 얼굴 감지 (기본)\", \"haarcascade_frontalface_default.xml\"),\n",
    "    (\"전신 감지\", \"haarcascade_fullbody.xml\"),\n",
    "    (\"왼쪽 눈 감지 (두 부분으로 분리)\", \"haarcascade_lefteye_2splits.xml\"),\n",
    "    (\"러시아 차량 번호판 감지 (16단계)\", \"haarcascade_license_plate_rus_16stages.xml\"),\n",
    "    (\"하반신 감지\", \"haarcascade_lowerbody.xml\"),\n",
    "    (\"측면 얼굴(프로필) 감지\", \"haarcascade_profileface.xml\"),\n",
    "    (\"오른쪽 눈 감지 (두 부분으로 분리)\", \"haarcascade_righteye_2splits.xml\"),\n",
    "    (\"러시아 번호판 감지\", \"haarcascade_russian_plate_number.xml\"),\n",
    "    (\"웃는 표정 감지\", \"haarcascade_smile.xml\")\n",
    "]\n",
    "\n",
    "def detect_face(image_arr, scale_factor, min_neighbors, min_size) :\n",
    "    # read-only 배열을 writable 배열로 변환\n",
    "    image_arr = image_arr.copy()\n",
    "\n",
    "    # detectMultiScale는 이미지를 줄이고 Face를 찾는 과정을 반복한다.\n",
    "    # 전달 파라미터 중, scaleFactor는 이미지를 줄이는 비율을 의미. (보통 1.1~1.3으로 적용하고, 비율 작을수록 정확하지만 연산 속도 느림\n",
    "    # minNeighbors : 객체(얼굴)로 인정하기 위해 최소한 몇 번의 인접한 검출 사각형이 있어야 하는지를 지정. (이 값이 높을수록 오탐지는 줄지만, 정확한 감지 기회도 줄어들 수 있음.)\n",
    "    # minSize : 감지할 객체의 최소 크기를 튜플 (width, height)로 지정. 이보다 작은 객체는 무시합니다.\n",
    "    # maxSize : 감지할 객체의 최대 크기를 지정. 이보다 큰 객체는 무시합니다.\n",
    "    bounding_boxes = face_cascade.detectMultiScale(\n",
    "        image=image_arr,\n",
    "        scaleFactor=scale_factor,\n",
    "        minNeighbors=min_neighbors,\n",
    "        minSize=(min_size, min_size)\n",
    "    )\n",
    "    \"\"\"\n",
    "    # a는 detectMultiScale와 같은 좌표. b는 검출된 각 face의 신뢰도를 의미\n",
    "    a, b = face_cascade.detectMultiScale2(\n",
    "        image=image_arr,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(50, 50)\n",
    "    )\n",
    "\n",
    "    # a는 detectMultiScale와 같은 좌표. b는 검출된 각 face의 신뢰도를 의미. c는 가중치 값\n",
    "    a, b, c = face_cascade.detectMultiScale3(\n",
    "        image=image_arr,\n",
    "        scaleFactor=1.1,\n",
    "        minNeighbors=5,\n",
    "        minSize=(50, 50),\n",
    "        outputRejectLevels=True\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    for bounding_box in bounding_boxes : \n",
    "        x, y, w, h =  bounding_box\n",
    "\n",
    "        # 이미지에 바운딩 박스 그리기(색상은 BGR순. 마지막 3은 바운딩박스 테두리 굵기)\n",
    "        cv2.rectangle(image_arr, (x, y), (x + w, y + h), (0,255,0), 3)\n",
    "\n",
    "    # 웹캠에서 받아오는 이미지가 RGB 형태이면, 아래 코드 주석. BRG이면 아래 코드 실행.\n",
    "    # COLOR_BGR2RGB = BRG 형식을 RGB 형태로 변환\n",
    "    #image_arr = cv2.cvtColor(image_arr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return image_arr\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo : \n",
    "    DEFAULT_SCALE_FACTOR = 1.1\n",
    "    DEFAULT_MIN_NEIGHBORS = 6\n",
    "    DEFAULT_MIN_SIZE = 50\n",
    "\n",
    "    # 각 컴포넌트 이벤트 발생 시, inputs 또는 outputs에는 컴포넌트만 전달할 수 있음.\n",
    "    scale_factor =  gr.State(DEFAULT_SCALE_FACTOR)\n",
    "    min_neighbors = gr.State(DEFAULT_MIN_NEIGHBORS)\n",
    "    min_size = gr.State(DEFAULT_MIN_SIZE)\n",
    "    \n",
    "    # 웹캠에서 실시간으로 이미지를 읽어와, 유형별로 감지된 이미지를 return\n",
    "    def stream_webcam(image_arr, scale_factor, min_neighbors, min_size) : \n",
    "        result_image = detect_face(image_arr, scale_factor, min_neighbors, min_size)\n",
    "        return result_image\n",
    "    \n",
    "    def change_cascade(value) : \n",
    "        # 감지 유형 변경 시, global 변수의 값을 변경한다.\n",
    "        # 변경된 값으로 detect_face내에서, 감지하므로 정상 적용됨\n",
    "        global face_cascade\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + value)\n",
    "        return value\n",
    "    \n",
    "    # 사용자가 입력한 옵션값 적용\n",
    "    def click_apply(scale_factor, min_neighbors, min_size) :\n",
    "        return float(scale_factor), int(min_neighbors), int(min_size)\n",
    "\n",
    "    gr.Markdown(\"# OpenCV를 활용한 실시간 객체 감지\")\n",
    "\n",
    "    cascade_dropdown = gr.Dropdown(label=\"유형 선택\", choices=HARR_CASCADES, value=\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "    with gr.Row() :\n",
    "        scale_factor_textbox = gr.Textbox(label=\"scaleFactor\", value=DEFAULT_SCALE_FACTOR)\n",
    "        min_neighbors_textbox = gr.Textbox(label=\"minNeighbors\", value=DEFAULT_MIN_NEIGHBORS)\n",
    "        min_size_text = gr.Textbox(label=\"minSize\", value=DEFAULT_MIN_SIZE)\n",
    "\n",
    "    apply_button = gr.Button(\"상수값 적용\")\n",
    "        \n",
    "    with gr.Row() :\n",
    "        # 디바이스의 캠을 이용하여, 실시간으로 웹캠의 화면을 Image Array 형태로 받아옴.\n",
    "        stream_image = gr.Image(label=\"실시간 웹캠\", sources=\"webcam\", streaming=True)\n",
    "\n",
    "        # 웹캠에서 Face 감지 결과를 표출할 컴포넌트\n",
    "        result_image = gr.Image(label=\"검출 결과\", interactive=False)\n",
    "\n",
    "    stream_image.stream(fn=stream_webcam, inputs=[stream_image, scale_factor, min_neighbors, min_size], outputs=[result_image])\n",
    "    cascade_dropdown.change(fn=change_cascade, inputs=[cascade_dropdown], outputs=[cascade_dropdown])\n",
    "    apply_button.click(fn=click_apply, inputs=[scale_factor_textbox, min_neighbors_textbox, min_size_text], outputs=[scale_factor, min_neighbors, min_size])\n",
    "\n",
    "demo.launch()\n",
    "\n",
    "\n",
    "#result_image = detect_face(image_arr = cv2.imread(\"files/test6.jpg\"))\n",
    "#pil_image = Image.fromarray(result_image)\n",
    "#pil_image"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
